{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002159F51BEF0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002159F52BE10>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002159F52B898>)\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.00784314  0.55686277  0.98039222  0.20392159  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.08627451  0.59607846  0.99607849  0.99607849  0.33333334  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.09803922  0.55686277  0.99607849  0.99607849  0.75686282  0.11764707\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.01568628  0.57647061  0.99607849  0.99607849  0.57647061  0.02352941\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.5411765   0.99607849  0.99607849  0.59215689  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.50196081  0.99215692  0.99607849  0.57254905  0.01960784  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.21960786  0.92549026  0.99607849  0.59215689  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.72549021  0.99607849  0.69411767  0.10588236  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.90196085  0.99607849  0.3019608   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.29411766  0.99607849  0.67058825  0.00392157  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.61176473  0.99607849  0.34901962  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.00784314  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.68627453  0.99607849  0.27450982  0.          0.          0.          0.\n",
      "  0.          0.22352943  0.627451    0.73333335  0.07058824  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.06666667  0.94901967  0.99607849  0.27450982  0.          0.          0.\n",
      "  0.04313726  0.84313732  0.97254908  0.99607849  0.99607849  0.62352943\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.08235294  0.99607849  0.99607849  0.27450982  0.          0.\n",
      "  0.34901962  0.80392164  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.68235296  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.04313726  0.84313732  0.99607849  0.27450982\n",
      "  0.05490196  0.39607847  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.64313728  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.68627453\n",
      "  0.99607849  0.7843138   0.86666673  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.80392164  0.08627451  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.28627452  0.98431379  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.98823535  0.59607846  0.08627451  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.90196085  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99215692  0.64313728  0.29803923  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.90196085  0.99607849  0.61176473\n",
      "  0.43137258  0.04313726  0.03529412  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.90196085  0.42745101\n",
      "  0.01176471  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(mnist)\n",
    "print(mnist.train.images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_digit(num):\n",
    "    print(mnist.train.labels[num])\n",
    "    label = mnist.train.labels[num].argmax(axis=0)\n",
    "    image = mnist.train.images[num].reshape([28,28])\n",
    "    plt.title('Example: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb5Yoh98sUQ6/WaL+H6I/vLFO7oVZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2159d512ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display_digit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9187\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Deep MNIST tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.74\n",
      "step 200, training accuracy 0.96\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.96\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.98\n",
      "step 900, training accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
